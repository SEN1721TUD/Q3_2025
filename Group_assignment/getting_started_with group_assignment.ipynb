{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEN1721 2025 Group assignment 3\n",
    "#### This notebook aims to get you started with the assigmnent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme.expressions import Beta, PanelLikelihoodTrajectory\n",
    "\n",
    "# Import custom estimation functions for Biogeme\n",
    "from bio_estimation_fcns import estimate_mnl, estimate_LC, print_results, create_collage\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "from random import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the data sets\n",
    "\n",
    "# Path to the folder of the choice data set and segmentation data set\n",
    "data_path = Path(os.getcwd()+'/data') # Make sure to change this to your own path\n",
    "print(data_path)\n",
    "\n",
    "# Path to the folder of the images\n",
    "img_path = Path(os.getcwd()+'/data/raw_images') # Make sure to change this to your own path\n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the choice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path / 'SEN1721_LC_group_assignment_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Descriptive analysis of choice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of choice task per individual\n",
    "print(f\"There are {df['RID'].nunique()} individuals in the dataset\")\n",
    "print(f\"The number of choice tasks per individual is:\")\n",
    "print(df['RID'].value_counts().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the image segmentation & depth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img = pd.read_csv(data_path / 'images_SEN1721.csv')\n",
    "df_img.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Descriptive analysis of segmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random sample of images given a threshold condition\n",
    "N_images = 30 # Define the number of images to show\n",
    "cols = 5 # Define the number of columns in the collage (cols x rows <= N_images)\n",
    "rows = 5 # Define the number of rows in the collage (cols x rows <= N_images)\n",
    "\n",
    "# Define a list of segmentation to show\n",
    "cols_show = ['BUILDING','GRASS']# ,'WATER','ROAD','SKY','TREES','PERSON','TRUCK'] # Modify to show different segmentations\n",
    "\n",
    "# Define the threshold level for the quantile\n",
    "quantile_threshold_level = 0.99 # Modify this threshold level to show different images\n",
    "\n",
    "# Loop over the list\n",
    "for col in cols_show:\n",
    "\n",
    "    # Set the threshold level\n",
    "    threshold = df_img[col].quantile(quantile_threshold_level)\n",
    "    \n",
    "    # Filter the images based on the threshold condition\n",
    "    df_cond = df_img[df_img[col] >= threshold]\n",
    "    print(f'There are {len(df_cond)} images satisfying the condition {col} >= {threshold:0.3f}')\n",
    "\n",
    "    # Check if there are enough images to show and if the number of columns and rows is less than the number of images\n",
    "    if len(df_cond) > N_images and (cols * rows) <= N_images:\n",
    "        \n",
    "        # Randomly sample N_images from df_cond\n",
    "        df_sample = df_cond.sample(N_images) # Random sample of N_images\n",
    "\n",
    "        # Show the images in a collage\n",
    "        create_collage(img_path,\n",
    "                        df_sample['IMG'], \n",
    "                        txt = df_sample['IMG'],\n",
    "                        cols = cols,\n",
    "                        rows = rows)\n",
    "    elif len(df_cond) <= N_images:\n",
    "        print(f'There are not enough images to show: {len(df_cond)} < {N_images}')\n",
    "    elif (cols * rows) > N_images:\n",
    "        print(f'cols * rows = {cols * rows} is greater than N_images = {N_images}. Adjust the number of columns and rows') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Descriptive analysis of depth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with the depth information\n",
    "col_depth = [col for col in df_img.columns if 'DIST' in col]\n",
    "col_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the depth features\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "cols_depth_fig = ['MIN_DISTANCE', 'MEAN_DISTANCE', 'MAX_DISTANCE']\n",
    "for i, col in enumerate(cols_depth_fig):\n",
    "    ax[i].hist(df_img[col], bins=50, edgecolor='black', rwidth=0.80)\n",
    "    ax[i].set_ylabel('Count')\n",
    "    ax[i].set_xlabel(col)\n",
    "    ax[i].grid()\n",
    "    ax[i].set_axisbelow(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random sample of images given a threshold condition\n",
    "N_images = 30 # Define the number of images to show\n",
    "cols = 5 # Define the number of columns in the collage (cols x rows <= N_images)\n",
    "rows = 5 # Define the number of rows in the collage (cols x rows <= N_images)\n",
    "\n",
    "# Define a list of depth statitics to show\n",
    "cols_depth_collage = ['MIN_MAX_DIST', 'MAX_MAX_DIST']\n",
    "\n",
    "# Loop over the list\n",
    "for col in cols_depth_collage:\n",
    "\n",
    "    # Filter the images based on the condition\n",
    "    df_cond = df_img[df_img[col] == 1]\n",
    "    \n",
    "    # Randomly sample N_images from df_cond\n",
    "    df_sample = df_cond.sample(N_images) # Random sample of N_images\n",
    "\n",
    "    # Show the images in a collage\n",
    "    print(f'Random sample of {N_images} images from the 10% quantile of images with the {col}')\n",
    "    create_collage(img_path,\n",
    "                    df_sample['IMG'], \n",
    "                    txt = df_sample['IMG'],\n",
    "                    cols = cols,\n",
    "                    rows = rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimate discrete choice models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme database object\n",
    "# list of columns that arenot objects\n",
    "cols = df.columns[df.dtypes != 'object']\n",
    "biodata = db.Database('data', df.loc[:,cols])\n",
    "\n",
    "# Create biogeme variables\n",
    "for c in cols:\n",
    "    globals()[c] = biodata.variables[c]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Linear-additive RUM-MNL model:\n",
    "Note that in the utility function, we divide the monthly cost (C) and the travel time (TT) by 225 and 15 respectively. These are the maximum values for these variables in the data. Hence they are rescaled such that they are between -1 and 1. This makes the estimation process more stable. <br>\n",
    "However, it is important to remember that the estimated coefficients should be multiplied by 225 and 15 when interpreting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a name to the model    \n",
    "model_name = 'Linear-additive RUM-MNL, with min-max depth combinations'\n",
    "\n",
    "# Define the model parameters, using the function \"Beta()\", in which you must define:\n",
    "B_hhc = Beta('B_hhc', 0, None, None, 0)\n",
    "B_tti = Beta('B_tti', 0, None, None, 0)\n",
    "B_max_min_dist =  Beta('B_max_min_dist', 0, None, None, 0)\n",
    "B_min_max_dist =  Beta('B_min_max_dist', 0, None, None, 0)\n",
    "B_max_max_dist =  Beta('B_max_max_dist', 0, None, None, 0)\n",
    "\n",
    "# Define the utility functions\n",
    "V1 = B_hhc * (C1/225) + B_tti * (TT1/15) + B_max_min_dist * MAX_MIN_DIST1 + B_min_max_dist * MIN_MAX_DIST1 + B_max_max_dist * MAX_MAX_DIST1    \n",
    "V2 = B_hhc * (C2/225) + B_tti * (TT2/15) + B_max_min_dist * MAX_MIN_DIST2 + B_min_max_dist * MIN_MAX_DIST2 + B_max_max_dist * MAX_MAX_DIST2\n",
    "\n",
    "# Associate utility functions with the numbering of alternatives\n",
    "V  = {1: V1, 2: V2}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: 1, 2: 1}\n",
    "\n",
    "# Estimate the model\n",
    "results = estimate_mnl(V, AV, CHOICE,biodata,model_name)\n",
    "print_results(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Latent class models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[df.dtypes != 'object']\n",
    "biodata_panel = db.Database('data_panel', df.loc[:,cols])\n",
    "biodata_panel.panel(\"RID\")\n",
    "\n",
    "# Create biogeme variables\n",
    "for c in cols:\n",
    "    globals()[c] = biodata_panel.variables[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a name to the model    \n",
    "model_name = 'LC with 2 classes'\n",
    "\n",
    "# Define the model parameters, using the function \"Beta()\", in which you must define:\n",
    "B_hhc_0 = Beta('B_hhc_0', -0.05, None, None, 0)\n",
    "B_tti_0 = Beta('B_tti_0', -0.05, None, None, 0)\n",
    "B_max_min_dist_0 =  Beta('B_max_min_dist_0', 0, None, None, 0)\n",
    "B_min_max_dist_0 =  Beta('B_min_max_dist_0', 0, None, None, 0)\n",
    "B_max_max_dist_0 =  Beta('B_max_max_dist_0', 0, None, None, 0)\n",
    "\n",
    "B_hhc_1 = Beta('B_hhc_1', -0.10, None, None, 0)\n",
    "B_tti_1 = Beta('B_tti_1', -0.10, None, None, 0)\n",
    "B_max_min_dist_1 =  Beta('B_max_min_dist_1', 0, None, None, 0)\n",
    "B_min_max_dist_1 =  Beta('B_min_max_dist_1', 0, None, None, 0)\n",
    "B_max_max_dist_1 =  Beta('B_max_max_dist_1', 0, None, None, 0)\n",
    "\n",
    "# Define the membership model parameters\n",
    "delta_0 = Beta('delta_0',  0   , None, None, 1)\n",
    "delta_1 = Beta('delta_1',  0.10, None, None, 0)\n",
    "gamma_gender_1 = Beta('gamma_gender_1', 0, None, None, 0)\n",
    "\n",
    "# Define utility functions for each class\n",
    "V1_0 = B_hhc_0 * (C1 / 225) + B_tti_0 * (TT1 / 15) + B_max_min_dist_0 * MAX_MIN_DIST1 + B_min_max_dist_0 * MIN_MAX_DIST1 + B_max_max_dist_0 * MAX_MAX_DIST1\n",
    "V2_0 = B_hhc_0 * (C2 / 225) + B_tti_0 * (TT2 / 15) + B_max_min_dist_0 * MAX_MIN_DIST2 + B_min_max_dist_0 * MIN_MAX_DIST2 + B_max_max_dist_0 * MAX_MAX_DIST2\n",
    "\n",
    "V1_1 = B_hhc_1 * (C1 / 225) + B_tti_1 * (TT1 / 15) + B_max_min_dist_1 * MAX_MIN_DIST1 + B_min_max_dist_1 * MIN_MAX_DIST1 + B_max_max_dist_1 * MAX_MAX_DIST1\n",
    "V2_1 = B_hhc_1 * (C2 / 225) + B_tti_1 * (TT2 / 15) + B_max_min_dist_1 * MAX_MIN_DIST2 + B_min_max_dist_1 * MIN_MAX_DIST2 + B_max_max_dist_1 * MAX_MAX_DIST2\n",
    "\n",
    "# Create a dictionary associating utility functions with the numbering of alternatives in the \"choice\" column\n",
    "V_0 = {1: V1_0, 2: V2_0}\n",
    "V_1 = {1: V1_1, 2: V2_1}\n",
    "\n",
    "# Put the dictionaries of utility functions in a list\n",
    "V = [V_0, V_1]\n",
    "\n",
    "# Create a dictionary to describe the availability conditions of each alternative, where 1 indicates that the alternative is available, and 0 indicates that the alternative is not available.\n",
    "AV = {1: 1, 2: 1} \n",
    "\n",
    "# Membership value-functions\n",
    "# The term \"PanelLikelihoodTrajectory(GENDER)**(1/(PanelLikelihoodTrajectory(T)))\" is a bit strange. But, it is the \"trick\" to include the covariate in the membership function.\n",
    "# It first multiplies the covariate over all rows in the database for each individual: PanelLikelihoodTrajectory(GENDER). Then, it undoes the multiplication by taking it to the power of (1/(PanelLikelihoodTrajectory(T))). \n",
    "# Unlike in-class assignment 2, in these data the number of choice tasks per individual is NOT the same for all individuals. Therefore, we added a variable in the data called \"T\". When T is taken to the power of the number of rows per individual, it generates the number of choice tasks per individual.\n",
    "# For example, suppose an individual has 3 choice tasks. Then, the value of PanelLikelihoodTrajectory(T) must equal 3. To accomplish this, T = 1.732051. When T is then taken to the power of 3, it equals 3.    \n",
    "# The result is a the covariate for each individual available at the panel level (as opposed to the observation level).\n",
    "nu_0 = delta_0 # Note: one class needs to be fixed to 0. delta_0 is fixed to 0\n",
    "nu_0 = delta_0\n",
    "nu_1 = delta_1 + gamma_gender_1 * PanelLikelihoodTrajectory(GENDER)**(1/(PanelLikelihoodTrajectory(T)))\n",
    "\n",
    "# Put membership functions in a list\n",
    "nu = [nu_0, nu_1]\n",
    "\n",
    "# Estimate the LC model\n",
    "results_LC = estimate_LC(V,AV,nu,CHOICE, biodata_panel,model_name)\n",
    "\n",
    "# Print the results\n",
    "print_results(results_LC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
